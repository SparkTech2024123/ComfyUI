"""
é«˜æ•ˆæ•°æ®ä¼ è¾“èŠ‚ç‚¹é›†åˆ
æ”¯æŒå…±äº«å†…å­˜ã€pickleåºåˆ—åŒ–ã€å†…å­˜æ˜ å°„ç­‰æ–¹å¼è¿›è¡Œæœ¬åœ°é«˜é€Ÿæ•°æ®ä¼ è¾“
é€‚ç”¨äºå®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨åœ¨åŒä¸€å°æœºå™¨ä¸Šçš„åœºæ™¯
"""

import torch
import numpy as np
import comfy.utils
import time
import json
import pickle
import tempfile
import os
import uuid
import hashlib
from multiprocessing import shared_memory
from PIL import Image, ImageOps
import io
import cv2

class LoadImageSharedMemory:
    """
    é€šè¿‡å…±äº«å†…å­˜åŠ è½½å›¾åƒæ•°æ® - æœ€é«˜æ€§èƒ½æ–¹æ¡ˆ
    æ”¯æŒå•å›¾å’Œå¤šå›¾æ‰¹é‡åŠ è½½
    """
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "shm_name": ("STRING", {"default": "", "tooltip": "å…±äº«å†…å­˜å—åç§°ï¼Œå¤šä¸ªåç§°ç”¨é€—å·åˆ†éš”"}),
                "shape": ("STRING", {"default": "[1080,1920,3]", "tooltip": "å›¾åƒå½¢çŠ¶ [height,width,channels]"}),
                "dtype": ("STRING", {"default": "uint8", "tooltip": "æ•°æ®ç±»å‹"}),
            },
            "optional": {
                "convert_bgr_to_rgb": ("BOOLEAN", {"default": True, "tooltip": "æ˜¯å¦å°†BGRæ ¼å¼è½¬æ¢ä¸ºRGBæ ¼å¼ (OpenCVé»˜è®¤ä½¿ç”¨BGR)"}),
                "batch_mode": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦å¯ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ˆå¤šå›¾åŠ è½½ï¼‰"}),
            }
        }

    CATEGORY = "api/image/efficient"
    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("image", "mask")
    FUNCTION = "load_image"
    
    def load_image(self, shm_name, shape, dtype, convert_bgr_to_rgb=True, batch_mode=False):
        if not shm_name or shm_name.strip() == "":
            raise ValueError("shm_name is required")

        try:
            # è§£æå‚æ•°
            shape_list = json.loads(shape)
            if len(shape_list) != 3:
                raise ValueError("Shape must be [height, width, channels]")

            height, width, channels = shape_list
            numpy_dtype = getattr(np, dtype)

            # å¤„ç†å…±äº«å†…å­˜åç§°ï¼ˆæ”¯æŒå¤šä¸ªåç§°ï¼‰
            shm_names = [name.strip() for name in shm_name.split(',') if name.strip()]

            if not shm_names:
                raise ValueError("No valid shared memory names provided")

            print(f"=== LoadImageSharedMemory Debug Info ===")
            print(f"Batch mode: {batch_mode}")
            print(f"Loading {len(shm_names)} image(s) from shared memory")
            print(f"Expected shape per image: {shape_list}")

            loaded_images = []

            # åŠ è½½æ¯ä¸ªå…±äº«å†…å­˜å—
            for i, current_shm_name in enumerate(shm_names):
                print(f"Loading image {i+1}/{len(shm_names)}: {current_shm_name}")

                # è¿æ¥åˆ°å…±äº«å†…å­˜
                shm = shared_memory.SharedMemory(name=current_shm_name)

                # ä»å…±äº«å†…å­˜é‡å»ºnumpyæ•°ç»„
                image_array = np.ndarray(shape_list, dtype=numpy_dtype, buffer=shm.buf)

                # å¤åˆ¶æ•°æ®ï¼ˆé¿å…å…±äº«å†…å­˜è¢«é‡Šæ”¾ï¼‰
                image_copy = image_array.copy()

                # å…³é—­å…±äº«å†…å­˜è¿æ¥ï¼ˆä¸åˆ é™¤ï¼‰
                shm.close()

                # BGRåˆ°RGBè½¬æ¢ (OpenCVé»˜è®¤ä½¿ç”¨BGRæ ¼å¼ï¼ŒComfyUIæœŸæœ›RGBæ ¼å¼)
                if convert_bgr_to_rgb and channels == 3:
                    image_copy = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)
                    print(f"  âœ“ Converted BGR to RGB for image {i+1}")

                # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
                if image_copy.dtype == np.uint8:
                    image_normalized = image_copy.astype(np.float32) / 255.0
                else:
                    image_normalized = image_copy.astype(np.float32)

                loaded_images.append(image_normalized)
                print(f"  âœ“ Successfully loaded image {i+1}: {image_copy.shape}")

            # æ ¹æ®æ¨¡å¼è¿”å›ç»“æœ
            if batch_mode and len(loaded_images) > 1:
                # æ‰¹å¤„ç†æ¨¡å¼ï¼šå°†æ‰€æœ‰å›¾åƒå †å ä¸ºä¸€ä¸ªæ‰¹æ¬¡
                batch_tensor = torch.from_numpy(np.stack(loaded_images, axis=0))
                batch_size = len(loaded_images)

                # åˆ›å»ºæ‰¹æ¬¡mask
                mask_tensor = torch.zeros((batch_size, height, width), dtype=torch.float32)

                print(f"âœ“ Batch mode: Created tensor with shape {batch_tensor.shape}")
                return (batch_tensor, mask_tensor)
            else:
                # å•å›¾æ¨¡å¼ï¼šåªè¿”å›ç¬¬ä¸€å¼ å›¾åƒï¼ˆå‘åå…¼å®¹ï¼‰
                image_tensor = torch.from_numpy(loaded_images[0]).unsqueeze(0)
                mask_tensor = torch.zeros((1, height, width), dtype=torch.float32)

                if len(loaded_images) > 1:
                    print(f"âš ï¸  Multiple images provided but batch_mode=False, only returning first image")

                print(f"âœ“ Single mode: Created tensor with shape {image_tensor.shape}")
                return (image_tensor, mask_tensor)

        except Exception as e:
            raise ValueError(f"Error loading image from shared memory: {e}")

    @classmethod
    def IS_CHANGED(s, shm_name, shape, dtype, convert_bgr_to_rgb=True, batch_mode=False):
        if shm_name and shm_name.strip():
            m = hashlib.sha256()
            m.update(shm_name.strip().encode('utf-8'))
            m.update(shape.encode('utf-8'))
            m.update(dtype.encode('utf-8'))
            m.update(str(convert_bgr_to_rgb).encode('utf-8'))
            m.update(str(batch_mode).encode('utf-8'))
            return m.digest().hex()
        return time.time()

class SaveImageSharedMemory:
    """
    å°†å›¾åƒæ•°æ®ä¿å­˜åˆ°å…±äº«å†…å­˜ - é«˜æ€§èƒ½æ•°æ®ä¼ è¾“æ–¹æ¡ˆ
    ç›¸æ¯” SaveImageWebsocket é¿å…äº† PNG ç¼–ç å’Œç½‘ç»œä¼ è¾“å¼€é”€
    """
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "images": ("IMAGE",),
            },
            "optional": {
                "shm_name": ("STRING", {"default": "", "tooltip": "å¯é€‰çš„å…±äº«å†…å­˜å—åç§°ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆ"}),
                "output_format": (["RGB", "RGBA", "BGR"], {"default": "RGB", "tooltip": "è¾“å‡ºå›¾åƒæ ¼å¼"}),
                "convert_rgb_to_bgr": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦å°†RGBè½¬æ¢ä¸ºBGRæ ¼å¼ (OpenCVå…¼å®¹)"}),
            }
        }

    RETURN_TYPES = ()
    FUNCTION = "save_images"
    OUTPUT_NODE = True
    CATEGORY = "api/image/efficient"

    def _safe_create_shared_memory(self, size, base_name, batch_number, max_retries=5):
        """
        Safely create shared memory with conflict resolution

        Args:
            size: Size of shared memory in bytes
            base_name: Base name for shared memory
            batch_number: Batch number for this image
            max_retries: Maximum number of retry attempts

        Returns:
            tuple: (SharedMemory object, actual name used)
        """
        for attempt in range(max_retries):
            try:
                # Generate unique name with timestamp and process ID for better uniqueness
                timestamp = int(time.time() * 1000000)  # microsecond precision
                process_id = os.getpid()

                if base_name and base_name.strip():
                    # Use provided base name with additional uniqueness
                    current_shm_name = f"{base_name.strip()}_{batch_number:03d}_{timestamp}_{process_id}"
                else:
                    # Generate completely unique name
                    current_shm_name = f"comfyui_output_{uuid.uuid4().hex[:16]}_{batch_number:03d}_{timestamp}_{process_id}"

                # Try to create shared memory
                shm = shared_memory.SharedMemory(create=True, size=size, name=current_shm_name)
                return shm, current_shm_name

            except FileExistsError:
                # Shared memory with this name already exists
                print(f"  âš ï¸  Shared memory name conflict (attempt {attempt + 1}): {current_shm_name}")

                # Try to clean up the existing segment
                try:
                    existing_shm = shared_memory.SharedMemory(name=current_shm_name)
                    existing_shm.close()
                    existing_shm.unlink()
                    print(f"  ğŸ—‘ï¸  Cleaned up existing shared memory: {current_shm_name}")
                except Exception as cleanup_error:
                    print(f"  âš ï¸  Failed to cleanup existing shared memory: {cleanup_error}")

                # Add small delay before retry
                time.sleep(0.001 * (attempt + 1))  # Progressive delay
                continue

            except Exception as e:
                if attempt == max_retries - 1:
                    raise ValueError(f"Failed to create shared memory after {max_retries} attempts: {e}")
                print(f"  âš ï¸  Shared memory creation error (attempt {attempt + 1}): {e}")
                time.sleep(0.001 * (attempt + 1))
                continue

        raise ValueError(f"Failed to create shared memory after {max_retries} attempts")

    def save_images(self, images, shm_name="", output_format="RGB", convert_rgb_to_bgr=False):
        try:
            # å¤„ç†æ‰¹å¤„ç†ä¸­çš„æ‰€æœ‰å›¾åƒ
            batch_size = images.shape[0]
            print(f"=== SaveImageSharedMemory Debug Info ===")
            print(f"Input images tensor shape: {images.shape}")
            print(f"Processing {batch_size} image(s) for shared memory storage")

            results = []

            # ä¸ºæ¯å¼ å›¾åƒåˆ›å»ºç‹¬ç«‹çš„å…±äº«å†…å­˜å—
            for batch_number, image_tensor in enumerate(images):
                # è½¬æ¢ä¸ºnumpyæ•°ç»„ (0-255 uint8èŒƒå›´)
                image_numpy = (image_tensor.cpu().numpy() * 255).astype(np.uint8)

                # æ ¼å¼è½¬æ¢
                if convert_rgb_to_bgr and image_numpy.shape[2] == 3:
                    image_numpy = cv2.cvtColor(image_numpy, cv2.COLOR_RGB2BGR)
                    print(f"âœ“ Converted RGB to BGR for image {batch_number}")

                # ä½¿ç”¨å®‰å…¨çš„å…±äº«å†…å­˜åˆ›å»ºæ–¹æ³•
                shm_size = image_numpy.nbytes
                shm, current_shm_name = self._safe_create_shared_memory(
                    size=shm_size,
                    base_name=shm_name,
                    batch_number=batch_number
                )

                # å°†æ•°æ®å†™å…¥å…±äº«å†…å­˜
                shm_array = np.ndarray(image_numpy.shape, dtype=image_numpy.dtype, buffer=shm.buf)
                shm_array[:] = image_numpy[:]

                # å…³é—­å…±äº«å†…å­˜è¿æ¥ï¼ˆä¿æŒæ•°æ®å­˜åœ¨ï¼‰
                shm.close()

                # å‡†å¤‡è¿”å›ä¿¡æ¯
                result_info = {
                    "shm_name": current_shm_name,
                    "shape": list(image_numpy.shape),
                    "dtype": str(image_numpy.dtype),
                    "format": output_format,
                    "size_bytes": shm_size,
                    "size_mb": round(shm_size / 1024 / 1024, 2),
                    "batch_number": batch_number
                }

                results.append(result_info)

                print(f"âœ“ Image {batch_number} saved to shared memory: {current_shm_name}")
                print(f"  - Shape: {image_numpy.shape}")
                print(f"  - Size: {result_info['size_mb']} MB")
                print(f"  - Format: {output_format}")

            print(f"âœ“ Successfully processed {len(results)} image(s) to shared memory")

            return {"ui": {"shared_memory_info": results}}

        except Exception as e:
            raise ValueError(f"Error saving images to shared memory: {e}")

    @classmethod
    def IS_CHANGED(s, images, shm_name="", output_format="RGB", convert_rgb_to_bgr=False):
        return time.time()

class SaveLatentSharedMemory:
    """
    å°†latentæ•°æ®ä¿å­˜åˆ°å…±äº«å†…å­˜ - é«˜æ€§èƒ½æ•°æ®ä¼ è¾“æ–¹æ¡ˆ
    """
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "samples": ("LATENT",),
            },
            "optional": {
                "shm_name": ("STRING", {"default": "", "tooltip": "å¯é€‰çš„å…±äº«å†…å­˜å—åç§°ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆ"}),
            }
        }

    RETURN_TYPES = ()
    FUNCTION = "save_latent"
    OUTPUT_NODE = True
    CATEGORY = "api/latent/efficient"

    def save_latent(self, samples, shm_name=""):
        try:
            # è·å–latent tensor
            latent_tensor = samples["samples"]
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            latent_numpy = latent_tensor.cpu().numpy()
            
            # ç”Ÿæˆå…±äº«å†…å­˜åç§°ï¼ˆå¦‚æœæœªæä¾›ï¼‰
            if not shm_name or shm_name.strip() == "":
                shm_name = f"latent_{uuid.uuid4().hex[:16]}"
            else:
                shm_name = shm_name.strip()
            
            # åˆ›å»ºå…±äº«å†…å­˜å—
            shm_size = latent_numpy.nbytes
            shm = shared_memory.SharedMemory(create=True, size=shm_size, name=shm_name)
            
            # å°†æ•°æ®å†™å…¥å…±äº«å†…å­˜
            shm_array = np.ndarray(latent_numpy.shape, dtype=latent_numpy.dtype, buffer=shm.buf)
            shm_array[:] = latent_numpy[:]
            
            # å…³é—­å…±äº«å†…å­˜è¿æ¥ï¼ˆä¿æŒæ•°æ®å­˜åœ¨ï¼‰
            shm.close()
            
            # å‡†å¤‡è¿”å›ä¿¡æ¯
            result_info = {
                "shm_name": shm_name,
                "shape": list(latent_numpy.shape),
                "dtype": str(latent_numpy.dtype),
                "size_bytes": shm_size
            }
            
            # è¿”å›å…±äº«å†…å­˜ä¿¡æ¯
            results = [result_info]
            
            return {"ui": {"latent_shm_info": results}}
            
        except Exception as e:
            raise ValueError(f"Error saving latent to shared memory: {e}")

    @classmethod
    def IS_CHANGED(s, samples, shm_name=""):
        return time.time()

class LoadLatentSharedMemory:
    """
    ä»å…±äº«å†…å­˜åŠ è½½latentæ•°æ® - é«˜æ€§èƒ½æ•°æ®ä¼ è¾“æ–¹æ¡ˆ
    """
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "shm_name": ("STRING", {"default": "", "tooltip": "å…±äº«å†…å­˜å—åç§°"}),
                "shape": ("STRING", {"default": "[1,4,64,64]", "tooltip": "Latentå½¢çŠ¶ [batch,channels,height,width]"}),
                "dtype": ("STRING", {"default": "float32", "tooltip": "æ•°æ®ç±»å‹"}),
            }
        }

    RETURN_TYPES = ("LATENT",)
    FUNCTION = "load_latent"
    CATEGORY = "api/latent/efficient"

    def load_latent(self, shm_name, shape, dtype):
        if not shm_name or shm_name.strip() == "":
            raise ValueError("shm_name is required")
        
        try:
            # è§£æå‚æ•°
            shape_list = json.loads(shape)
            if not isinstance(shape_list, list) or len(shape_list) != 4:
                raise ValueError("Shape must be [batch, channels, height, width]")
            
            numpy_dtype = getattr(np, dtype)
            
            # è¿æ¥åˆ°å…±äº«å†…å­˜
            shm = shared_memory.SharedMemory(name=shm_name.strip())
            
            # ä»å…±äº«å†…å­˜é‡å»ºnumpyæ•°ç»„
            latent_array = np.ndarray(shape_list, dtype=numpy_dtype, buffer=shm.buf)
            
            # å¤åˆ¶æ•°æ®ï¼ˆé¿å…å…±äº«å†…å­˜è¢«é‡Šæ”¾ï¼‰
            latent_copy = latent_array.copy()
            
            # å…³é—­å…±äº«å†…å­˜è¿æ¥ï¼ˆä¸åˆ é™¤ï¼‰
            shm.close()
            
            # è½¬æ¢ä¸ºtorch tensor
            latent_tensor = torch.from_numpy(latent_copy).float()
            
            return ({"samples": latent_tensor},)
            
        except Exception as e:
            raise ValueError(f"Error loading latent from shared memory: {e}")

    @classmethod
    def IS_CHANGED(s, shm_name, shape, dtype):
        if shm_name and shm_name.strip():
            m = hashlib.sha256()
            m.update(shm_name.strip().encode('utf-8'))
            m.update(shape.encode('utf-8'))
            m.update(dtype.encode('utf-8'))
            return m.digest().hex()
        return time.time()

    @classmethod
    def VALIDATE_INPUTS(s, shm_name, shape, dtype):
        if not shm_name or shm_name.strip() == "":
            return "shm_name is required"
            
        try:
            shape_list = json.loads(shape)
            if not isinstance(shape_list, list) or len(shape_list) != 4:
                return "Shape must be [batch, channels, height, width]"
        except json.JSONDecodeError:
            return "Invalid shape format, must be valid JSON list"
        
        try:
            getattr(np, dtype)
        except AttributeError:
            return f"Invalid dtype: {dtype}"
        
        return True

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "LoadImageSharedMemory": LoadImageSharedMemory,
    "SaveImageSharedMemory": SaveImageSharedMemory,
    "SaveLatentSharedMemory": SaveLatentSharedMemory,
    "LoadLatentSharedMemory": LoadLatentSharedMemory,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "LoadImageSharedMemory": "Load Image (Shared Memory)",
    "SaveImageSharedMemory": "Save Image (Shared Memory)",
    "SaveLatentSharedMemory": "Save Latent (Shared Memory)",
    "LoadLatentSharedMemory": "Load Latent (Shared Memory)",
} 